---
layout:     post
title:      PyTorch-动态计算图
subtitle:   动态图运算演示
date:       2019-04-26
author:     zhouchen
header-img: img/post-bg-pytorch.png
catalog: true
tags:
    - PyTorch
---

# 动态计算图
- 本案例主要对PyTorch进行一个动态运算的演示。
- 介绍
	- 由于这部分属于PyTorch的独有内容，TensorFlow没有此类特性，且没有理论介绍，这里简单介绍这个所谓的动态到底是什么。
	- 如果熟悉TensorFlow的使用流程就应该知道，先搭建网络结构（计算图），一旦搭建完成这个运算模式是不能改变的（当然dynamic_rnn是为了配合RNN网络的例外，但是本质上还是静态思维），数据在这个算图中流动，且输入输出的数据维度是固定的。其实很多时候这样就够了，静态图可以保证运算的高效率。
	- 但是总有一些例外如RNN，有时候RNN的time step是不一样的，设置train的时候batch_size也是不一样的。而在TensorFlow中可以使用上面的dynamic_rnn修改batch_size，但是time_step则不方便了，所以这样看来PyTorch确实有优势之处。
- 步骤
	- 定义RNN结构
		- 这里使用之前利用相差pi/2的三角函数进行预测的例子，在网络内部定义一个动态修改的time step长度。
		- 代码
			- ```python
				# 模型结构搭建
				class RNN(nn.Module):
				    def __init__(self):
				        super(RNN, self).__init__()
				
				        self.rnn = nn.RNN(
				            input_size=1,
				            hidden_size=32,
				            num_layers=1,
				            batch_first=True,
				        )
				        self.out = nn.Linear(32, 1)
				
				    def forward(self, x, h_state):
				        # x维度 (batch, time_step, input_size)
				        # h_state维度 (n_layers, batch, hidden_size)
				        # r_out维度 (batch, time_step, output_size)
				        r_out, h_state = self.rnn(x, h_state)
				        # 动态调整过程（在之前写RNN的时候，time_step是定长的，所以没有这一步）
				        outputs = []
				        for time_step in range(r_out.size(1)):
				            outputs.append(self.out(r_out[:, time_step, :]))
				        return torch.stack(outputs, dim=1), h_state
				
				
				rnn = RNN()
				print(rnn)
				```
	- 训练模型
		- 这里修改了模型训练的数据产生方式，使之长度随机。
		- 代码
			- ```python
				import torch.optim as optim
				optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)
				loss_func = nn.MSELoss()
				
				h_state = None
				%matplotlib qt5
				plt.figure(1, figsize=(12, 8))
				plt.ion()
				
				step = 0
				# 这里还是使用sin去预测cos
				for i in range(EPOCHS):
				    random_steps = np.random.randint(1, 4)  # 随机生成time steps
				    start, end = step * np.pi, (step + random_steps) * np.pi  # 不同time step
				    step += random_steps
				
				    steps = np.linspace(start, end, 10 * random_steps, dtype=np.float32)
				
				    print("this steps is {}".format(len(steps)))
				
				    x_np = np.sin(steps)
				    y_np = np.cos(steps)
				
				    x = torch.from_numpy(x_np[np.newaxis, :, np.newaxis])  # 维度(batch_size, time_step, input_size)
				    y = torch.from_numpy(y_np[np.newaxis, :, np.newaxis])
				
				    pred, h_state = rnn(x, h_state)
				    h_state = h_state.data
				
				    loss = loss_func(pred, y)
				    optimizer.zero_grad()
				    loss.backward() 
				    optimizer.step()
				    # 真实值预测值对比
				    plt.plot(steps, y_np, 'r-')
				    plt.plot(steps, pred.data.numpy().flatten(), 'b-')
				    plt.draw()
				    plt.pause(0.05)
				
				plt.ioff()
				plt.show()
				```
		- 运行结果
			- 可以看到，逐渐拟合。
			- ![](https://img-blog.csdnimg.cn/20190426170930314.gif)
- 补充说明
	- 本案例使用PyTorch框架，如果你是神经网络的新手建议你使用这个框架，上手容易，网络搭建结构化。（参考莫烦教程）
	- 本类框架案例均用代码和效果说话，关于神经网络的原理可以见我的其他博客。
	- 具体完整代码见我的Github，欢迎star或者fork。（开发环境为Jupyter）